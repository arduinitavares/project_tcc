
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Project Snapshot</title>
  <style>
        body { font-family: "Segoe UI", Arial, sans-serif; margin: 32px; color: #1a1a1a; }
        h1, h2, h3 { color: #0f172a; }
        .muted { color: #64748b; }
        .section { margin-top: 28px; }
        .card { border: 1px solid #e2e8f0; border-radius: 8px; padding: 16px; margin-top: 12px; }
        table { width: 100%; border-collapse: collapse; margin-top: 12px; }
        th, td { border: 1px solid #e2e8f0; padding: 8px; text-align: left; vertical-align: top; }
        th { background: #f8fafc; }
        pre { background: #f8fafc; padding: 12px; border-radius: 6px; overflow-x: auto; }
        .badge { display: inline-block; padding: 2px 8px; border-radius: 999px; font-size: 12px; }
        .badge-ok { background: #dcfce7; color: #166534; }
        .badge-warn { background: #fef9c3; color: #854d0e; }
        .toc li { margin-bottom: 4px; }
  </style>
</head>
<body>
  <h1>Project Snapshot</h1>
  <p class="muted">Generated at 2026-01-30T13:40:10.609220Z (UTC)</p>
  <div class="card">
    <h2>Review-First Human-in-the-Loop Extraction Pipeline</h2>
    <p></p>
    <p class="muted">Read-only snapshot of current project state.</p>
  </div>

  <div class="section">
    <h2>Executive Summary</h2>
    <div class="card">
      <p><strong>Story status:</strong> Total 4 | To Do 4 | In Progress 0 | Done 0 | Accepted 0</p>
      <p>No sprint data available.</p>
    </div>
  </div>

  <div class="section">
    <h2>Product Vision</h2>
    <div class="card"><pre>For technical and ML/data teams in industrial engineering organizations who need to extract structured data from complex engineering diagrams and documents but struggle to build trusted, auditable ML extraction workflows where human corrections are systematically captured as training data across all pipeline stages, Review-First Human-in-the-Loop Extraction Pipeline is a stage-gated, human-in-the-loop document and diagram extraction platform that turns routine human review into high-quality, auditable ground truth and training data while delivering extraction results users trust. Unlike traditional OCR/IDP tools and custom document-processing pipelines that bolt human review on as an exception path and lose corrections as silent overwrites, our product makes human review a first-class, stage-gated feature with immutable event-sourced deltas, gold snapshots at every checkpoint, and built-in training exports for continuous model retraining.</pre></div>
  </div>

  <div class="section">
    <h2>Roadmap</h2>
    <h3>Now</h3><div class="card"><strong>Now - Deployment, Operations &amp; Integration Tooling</strong><p class="muted">The first deploy must meet a minimum bar for industrial environments: Kubernetes/Helm-based on-prem or VPC deployment, no external call dependencies, basic monitoring/logging, and deterministic configuration. Those elements place this theme in Now, with additional hardening (air-gapped operation, stricter operational constraints) in Next and richer downstream publishing and opinionated connectors explicitly targeted for Later alongside schema/graph work.</p><p class="muted">Epics: 1 | Features: 6 | Stories: 0</p></div><div class="card"><strong>Now - Document Ingestion &amp; Versioned Storage</strong><p class="muted">Foundational for every other capability: you can’t have trusted review, provenance, or retraining without robust ingestion, versioning, and deterministic, hash-based linkage to specific document versions. Included explicitly in MVP (Now) to support the initial P&amp;ID-focused workflow and deterministic re-runs.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 4</p></div><div class="card"><strong>Now - Event-Sourced Review Deltas &amp; Immutable Gold Snapshots</strong><p class="muted">Central to the vision of turning routine review into trustworthy ground truth: the first deploy must include immutable deltas, replayability, and linkage to specific inputs/configs/models. This theme underpins replayable deltas, immutable revisions, and reviewer attribution required for early customers and for reliable training data construction.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 0</p></div><div class="card"><strong>Now - Primitive-Level ML Extraction Engine</strong><p class="muted">Core to the product’s value proposition: the human-in-the-loop workflow is only useful if there is a draft extraction to review and correct. MVP needs a solid but scope-limited extraction engine for P&amp;IDs, with electrical schematics and richer taxonomy extensibility to follow.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 0</p></div><div class="card"><strong>Now - Review-First Visual UI &amp; Stage-Gated Approvals</strong><p class="muted">This is the key differentiator versus traditional OCR/IDP: human review is first-class and stage-gated. MVP must deliver a compelling, efficient review experience so expert time is well used and the stage-gate workflow is actually adopted in production environments.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 0</p></div><div class="card"><strong>Now - Security, Permissions &amp; Collaboration Controls</strong><p class="muted">You called these out as missing but critical to capture before scheduling. Industrial customers will treat RBAC, collaboration controls, and data residency as non-negotiable for even the earliest deployments. This theme is therefore part of the MVP (Now) and tightly coupled with review UI, event sourcing, and deployment architecture.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 0</p></div><div class="card"><strong>Now - Training Data Export &amp; Continuous Retraining Integration</strong><p class="muted">The product must pay off in model improvement, not just review UX. MVP needs deterministic, reproducible exports of gold data, clear dataset versioning, and basic linkage to MLflow-style runs/models so teams can actually retrain and trace results. More advanced automation hooks and sophisticated experiment integrations can extend into Next once the core loop is proven in production.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 0</p></div><h3>Next</h3><div class="card"><strong>Next - Pipeline Provenance, Auditability &amp; Compliance Readiness</strong><p class="muted">Industrial buyers need a credible story for provenance and compliance, but only the basics are required for first deployment (hashing, immutable revisions, reviewer attribution, replayable deltas). Those basics are largely delivered via ingestion, event-sourcing, and security/permissions work in Now; this theme focuses on expanding into richer end-to-end provenance views, configurable retention, access logs, and exportable audit/compliance reports as a Next wave once the core loop is proven.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 0</p></div><h3>Later</h3><div class="card"><strong>Later - Schema-Driven Validation &amp; Graph Assembly</strong><p class="muted">You explicitly want to defer most schema/graph work until the review-first extraction loop and retraining payback are clearly validated. This is value-add for downstream digital twin/CMMS/simulation workflows, but it risks over-scoping the initial product. Only minimal internal consistency checks should be considered earlier, and full schema-driven graph assembly is targeted for a Later phase.</p><p class="muted">Epics: 1 | Features: 5 | Stories: 0</p></div>
  </div>

  <div class="section">
    <h2>Technical Spec</h2>
    <p class="muted">Status: <span class="badge badge-ok">approved</span></p>
    <table><tbody><tr><th>Spec version</th><td>1</td></tr><tr><th>Approved by</th><td>implicit</td></tr><tr><th>Approved at</th><td>2026-01-29 15:00:23.840602</td></tr><tr><th>Notes</th><td>Implicit approval</td></tr><tr><th>Content ref</th><td>test_specs\genai_spec.md</td></tr></tbody></table>
    <div class="card"><strong>Contents</strong><ul class="toc"><li>Review-First Human-in-the-Loop Extraction Pipeline</li><li>1. Objectives</li><li>2. Core Principle</li><li>3. Stage-Gated Review Workflow</li><li>3.1 Checkpoint A — Primitive Review</li><li>Machine Outputs</li><li>Review UI Requirements</li><li>User Actions</li><li>Exit Criteria</li><li>Outputs</li><li>3.2 Checkpoint B — Graph Assembly Review</li><li>Machine Outputs</li><li>Review UI Requirements</li><li>User Actions</li><li>Outputs</li><li>3.3 Checkpoint C — DEXPI Canonicalization Review</li><li>Machine Outputs</li><li>User Actions</li><li>Outputs</li><li>3.4 Checkpoint D — AAS Publishing Review</li><li>Machine Outputs</li><li>User Actions</li><li>Outputs</li><li>4. Review Action (Delta) Schema</li><li>ReviewAction (Draft)</li><li>5. Gold Dataset Generation</li><li>5.1 Detection Dataset</li><li>5.2 OCR Dataset</li><li>5.3 Classification Dataset</li><li>5.4 Association Dataset (future)</li><li>6. Active Learning &amp; Review Prioritization</li><li>6.1 Review Priority Scoring</li><li>6.2 Auto-Acceptance</li><li>7. User Experience &amp; Incentives</li><li>7.1 Review Load Control</li><li>7.2 Transparency &amp; Trust</li><li>7.3 Payback Loop</li><li>8. Versioning, Audit, and Provenance</li><li>8.1 Immutable Revisions</li><li>8.2 Event-Sourced State</li><li>9. Minimal MVP Definition</li><li>MVP-1: Primitive Review Loop</li><li>10. Definition of Done (Per Checkpoint)</li></ul></div>
    <div class="card"><pre># Review-First Human-in-the-Loop Extraction Pipeline  
**Technical Specification (Draft)**

---

## 1. Objectives

This system is designed around a **review-first, human-in-the-loop pipeline** to achieve the following goals:

1. Leverage user review effort as part of normal product usage  
2. Deliver outputs that users trust and are satisfied with  
3. Capture user feedback, confirmations, and corrections as explicit labels  
4. Produce high-quality, auditable datasets for continuous model retraining  

The pipeline is **stage-gated**, with explicit review checkpoints and immutable revisioning.

---

## 2. Core Principle

&gt; **Every pipeline stage must emit a reviewable artifact.**

Each stage produces:
- Machine output (model result)
- Human review artifact (visual + structured)
- Review delta (what changed)
- Gold snapshot (post-review ground truth)
- Training export (model-ready data)

Human review is not an exception path — it is a first-class system feature.

---

## 3. Stage-Gated Review Workflow

### 3.1 Checkpoint A — Primitive Review  
*(Detection + OCR + Style Classification)*

#### Machine Outputs
- Symbol bounding boxes
- Detection confidence
- Tag type / style code predictions
- OCR text (raw + normalized)
- Model provenance metadata

#### Review UI Requirements
- Page image with overlayed primitives
- Color-coded by confidence
- Hover details:
  - bbox coordinates
  - detection score
  - OCR text + confidence
  - tag_type + classification confidence

#### User Actions
- Add / delete primitive
- Move / resize bounding box
- Change primitive class / symbol type
- Edit OCR text
- Change tag_type / style code
- Explicitly waive validation warnings

#### Exit Criteria
- All blocking issues resolved or waived
- User approves **Checkpoint A**

#### Outputs
- `primitives_v{n}.jsonl | parquet`
- `review_actions_v{n}.jsonl`
- `gold_primitives_v{n}.jsonl`

---

### 3.2 Checkpoint B — Graph Assembly Review  
*(Topology &amp; Connectivity)*

#### Machine Outputs
- Nodes (equipment, instruments, junctions)
- Edges (pipes, signals, flows)
- Confidence and evidence per edge

#### Review UI Requirements
- Graph overlay on drawing
- Node/edge list with validation warnings:
  - orphan nodes
  - impossible connections
  - disconnected components

#### User Actions
- Add / remove edges
- Fix edge direction
- Merge / split nodes
- Confirm or waive graph validation issues

#### Outputs
- `graph_v{n}.json`
- `graph_review_actions_v{n}.jsonl`
- `gold_graph_v{n}.json`

---

### 3.3 Checkpoint C — DEXPI Canonicalization Review

#### Machine Outputs
- DEXPI objects mapped from graph nodes
- Schema validation results
- Traceability links to graph primitives

#### User Actions
- Correct object types
- Fill missing attributes
- Fix mapping inconsistencies

#### Outputs
- `dexpi_v{n}.xml | json`
- `dexpi_review_actions_v{n}.jsonl`

---

### 3.4 Checkpoint D — AAS Publishing Review

#### Machine Outputs
- AAS submodels
- Required field checklist per consumer
- Validation status

#### User Actions
- Confirm or edit metadata
- Approve publishing

#### Outputs
- `aas_v{n}.json | aasx`
- Consumer-ready export package

---

## 4. Review Action (Delta) Schema

All user feedback is stored as **event-sourced deltas**, never silent overwrites.

### ReviewAction (Draft)

- `action_id`: UUID
- `doc_id`
- `page_id` (nullable for graph/DEXPI)
- `checkpoint`: `primitive | graph | dexpi | aas`
- `target_type`: `primitive | node | edge | text`
- `target_id` (or temp_id for new objects)
- `action_type`:
  - `create`
  - `delete`
  - `update_geometry`
  - `update_class`
  - `update_text`
  - `update_attribute`
  - `link`
  - `unlink`
  - `approve`
  - `waive_issue`
- `before`: JSON (optional, recommended)
- `after`: JSON
- `reason` (optional):
  - `low_confidence`
  - `schema_mismatch`
  - `user_found`
  - `cleanup`
- `reviewer_id`
- `timestamp`
- `model_provenance`

---

## 5. Gold Dataset Generation

Each approved checkpoint produces **training-ready datasets**.

### 5.1 Detection Dataset
- Image
- Bounding boxes
- Classes
- Ignored regions (optional)
- Source: `gold_primitives`

### 5.2 OCR Dataset
- Cropped image
- Raw text
- Normalized text
- Human-edited flag

### 5.3 Classification Dataset
- Cropped image
- tag_type / style_code labels
- Multi-label components (if applicable)

### 5.4 Association Dataset (future)
- Positive and negative symbol↔text links

---

## 6. Active Learning &amp; Review Prioritization

### 6.1 Review Priority Scoring
Each item receives a `review_priority` based on:
- Low model confidence
- Business importance (e.g., tag regex match)
- Disagreement between sources
- Novel or rare class/style
- Validation rule violations

Only top-K items are **mandatory review**.

### 6.2 Auto-Acceptance
- Items above acceptance threshold auto-accepted
- Marked as `auto_accepted=true`
- Can be down-weighted during retraining

---

## 7. User Experience &amp; Incentives

### 7.1 Review Load Control
- Mandatory vs optional review queues
- Bulk accept / bulk edit tools
- Regex-based correction suggestions

### 7.2 Transparency &amp; Trust
- Per-page progress indicators
- Confidence heatmaps
- Clear indication of what will be retrained

### 7.3 Payback Loop
- Explicit messaging:
  - “Your corrections improve future results”
  - “This project legend will be reused”

---

## 8. Versioning, Audit, and Provenance

### 8.1 Immutable Revisions
Each checkpoint approval creates:
- `doc_revision_id`
- Input hash (PDF SHA-256)
- Model versions
- Config versions (DPI, thresholds, legend.yml)

### 8.2 Event-Sourced State
- Current state = replay(review_actions)
- Enables:
  - reproducibility
  - debugging
  - deterministic training exports

---

## 9. Minimal MVP Definition

### MVP-1: Primitive Review Loop
- Detection + classification only
- Review UI supports:
  - accept all
  - edit bbox
  - change tag_type
  - delete false positives
  - add missing primitive
- Outputs:
  - primitives
  - review deltas
  - gold dataset
- Training export:
  - COCO (detection)
  - cropped classification dataset

This MVP already satisfies the full **payback loop**.

---

## 10. Definition of Done (Per Checkpoint)

A checkpoint is complete when:
- User can review and correct outputs
- Corrections are stored as deltas
- Gold snapshot is produced
- Training export is reproducible
- Model provenance is recorded
- Validation issues are resolved or waived explicitly

---

**End of Specification**
</pre></div>
  </div>

  <div class="section">
    <h2>Compiled Spec Authority</h2>
    <div class="card"><p><strong>Compiler:</strong> 1.0.0</p><p><strong>Prompt hash:</strong> d0b5eccf5967d6fc47997822f8d2f400d20e9364b6d07ee553fa078885e51a97</p><h3>Scope Themes</h3><ul><li>review-first-human-in-the-loop</li><li>stage-gated-pipeline</li><li>event-sourced-deltas</li><li>immutable-revisioning</li></ul><h3>Invariants</h3><ul><li>INV-f99ab8f4fd4dc615: FORBIDDEN_CAPABILITY silent_overwrite</li><li>INV-d16615fb58757af8: REQUIRED_FIELD reviewable_artifact</li><li>INV-6c268de9999eef91: REQUIRED_FIELD doc_revision_id</li><li>INV-500f2135d8be6df1: FORBIDDEN_CAPABILITY mutable_revision</li></ul></div><h3>Compiled Authority JSON</h3><pre>{
  &quot;scope_themes&quot;: [
    &quot;review-first-human-in-the-loop&quot;,
    &quot;stage-gated-pipeline&quot;,
    &quot;event-sourced-deltas&quot;,
    &quot;immutable-revisioning&quot;
  ],
  &quot;invariants&quot;: [
    {
      &quot;id&quot;: &quot;INV-f99ab8f4fd4dc615&quot;,
      &quot;type&quot;: &quot;FORBIDDEN_CAPABILITY&quot;,
      &quot;parameters&quot;: {
        &quot;capability&quot;: &quot;silent_overwrite&quot;
      }
    },
    {
      &quot;id&quot;: &quot;INV-d16615fb58757af8&quot;,
      &quot;type&quot;: &quot;REQUIRED_FIELD&quot;,
      &quot;parameters&quot;: {
        &quot;field_name&quot;: &quot;reviewable_artifact&quot;
      }
    },
    {
      &quot;id&quot;: &quot;INV-6c268de9999eef91&quot;,
      &quot;type&quot;: &quot;REQUIRED_FIELD&quot;,
      &quot;parameters&quot;: {
        &quot;field_name&quot;: &quot;doc_revision_id&quot;
      }
    },
    {
      &quot;id&quot;: &quot;INV-500f2135d8be6df1&quot;,
      &quot;type&quot;: &quot;FORBIDDEN_CAPABILITY&quot;,
      &quot;parameters&quot;: {
        &quot;capability&quot;: &quot;mutable_revision&quot;
      }
    }
  ],
  &quot;eligible_feature_rules&quot;: [],
  &quot;gaps&quot;: [],
  &quot;assumptions&quot;: [],
  &quot;source_map&quot;: [
    {
      &quot;invariant_id&quot;: &quot;INV-f99ab8f4fd4dc615&quot;,
      &quot;excerpt&quot;: &quot;All user feedback is stored as event-sourced deltas, never silent overwrites.&quot;,
      &quot;location&quot;: &quot;Section 4&quot;
    },
    {
      &quot;invariant_id&quot;: &quot;INV-d16615fb58757af8&quot;,
      &quot;excerpt&quot;: &quot;Every pipeline stage must emit a reviewable artifact.&quot;,
      &quot;location&quot;: &quot;Section 2&quot;
    },
    {
      &quot;invariant_id&quot;: &quot;INV-6c268de9999eef91&quot;,
      &quot;excerpt&quot;: &quot;Each checkpoint approval creates:&quot;,
      &quot;location&quot;: &quot;Section 8.1&quot;
    },
    {
      &quot;invariant_id&quot;: &quot;INV-500f2135d8be6df1&quot;,
      &quot;excerpt&quot;: &quot;Immutable Revisions&quot;,
      &quot;location&quot;: &quot;Section 8.1&quot;
    }
  ],
  &quot;compiler_version&quot;: &quot;1.0.0&quot;,
  &quot;prompt_hash&quot;: &quot;d0b5eccf5967d6fc47997822f8d2f400d20e9364b6d07ee553fa078885e51a97&quot;
}</pre>
  </div>

  <div class="section">
    <h2>User Stories</h2>
    <table><thead><tr><th>ID</th><th>Title</th><th>Persona</th><th>Status</th><th>Points</th><th>Theme</th><th>Feature</th><th>Acceptance Criteria</th></tr></thead><tbody><tr><td>1</td><td>Story from session</td><td>user</td><td>To Do</td><td>2</td><td>Now - Document Ingestion &amp; Versioned Storage</td><td>Ingest PDFs and rasterized engineering diagrams (initially scanned/vector-exported P&amp;IDs and similar process diagrams)</td><td>- AC from session</td></tr><tr><td>2</td><td>Story from session</td><td>user</td><td>To Do</td><td>2</td><td>Now - Document Ingestion &amp; Versioned Storage</td><td>Ingest PDFs and rasterized engineering diagrams (initially scanned/vector-exported P&amp;IDs and similar process diagrams)</td><td>- AC from session</td></tr><tr><td>3</td><td>Ingest scanned and vector-exported P&amp;IDs and raster engineering diagrams</td><td>automation engineer</td><td>To Do</td><td></td><td>Now - Document Ingestion &amp; Versioned Storage</td><td>Ingest PDFs and rasterized engineering diagrams (initially scanned/vector-exported P&amp;IDs and similar process diagrams)</td><td>- User can upload a PDF, PNG, JPEG, or TIFF via the UI or API and the system returns a successful confirmation within the expected SLA (HTTP 200 for API or a visible success message in the UI).
- System auto-detects whether an uploaded PDF page is vector-exported or raster/scanned and records the detected type in the diagram metadata (e.g., &quot;vector&quot; or &quot;raster&quot;).
- For vector-exported pages the system runs the vector parser and extracts text/objects; for raster pages it runs OCR; the processing pipeline result is saved as a per-page searchable diagram artifact and an ingest status is set to &quot;processed&quot; or &quot;failed&quot;.
- The system produces and exposes metadata for each uploaded file including filename, upload timestamp, page count, processing method (vector|raster), and a processing status; the UI/API returns this metadata on request.
- If an uploaded file is corrupted, unsupported, or exceeds the configured size limit, the system returns a clear, actionable error message explaining the problem and suggested next steps.</td></tr><tr><td>4</td><td>Story from session</td><td>user</td><td>To Do</td><td>2</td><td>Now - Document Ingestion &amp; Versioned Storage</td><td>Ingest PDFs and rasterized engineering diagrams (initially scanned/vector-exported P&amp;IDs and similar process diagrams)</td><td>- AC from session</td></tr></tbody></table>
  </div>

  <div class="section">
    <h2>Sprint Status</h2>
    <p class="muted">No sprint data available.</p>
  </div>
</body>
</html>
